{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-17 00:26:13--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.6’\n",
      "\n",
      "input.txt.6         100%[===================>]   1.06M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2023-10-17 00:26:14 (16.0 MB/s) - ‘input.txt.6’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43]\n",
      "hello there\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encoded = lambda s: [stoi[c] for c in s]\n",
    "decoded = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "print(encoded(\"hello there\"))\n",
    "print(decoded(encoded(\"hello there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameya/Documents/LLMs/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor_data = torch.tensor(encoded(text), dtype=torch.long)\n",
    "print(tensor_data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56,  ..., 43, 56, 43]) tensor([12,  0,  0,  ..., 45,  8,  0])\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9*len(tensor_data))\n",
    "train = tensor_data[:n]\n",
    "valid = tensor_data[n:]\n",
    "print(train, valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train[:block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  tensor([18]) Target:  tensor(47)\n",
      "Context:  tensor([18, 47]) Target:  tensor(56)\n",
      "Context:  tensor([18, 47, 56]) Target:  tensor(57)\n",
      "Context:  tensor([18, 47, 56, 57]) Target:  tensor(58)\n",
      "Context:  tensor([18, 47, 56, 57, 58]) Target:  tensor(1)\n",
      "Context:  tensor([18, 47, 56, 57, 58,  1]) Target:  tensor(15)\n",
      "Context:  tensor([18, 47, 56, 57, 58,  1, 15]) Target:  tensor(47)\n",
      "Context:  tensor([18, 47, 56, 57, 58,  1, 15, 47]) Target:  tensor(58)\n"
     ]
    }
   ],
   "source": [
    "x = train[:block_size]\n",
    "y = train[1:block_size+1]\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(\"Context: \", context, \"Target: \", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "when input is [24] the target: 43\n",
      "when input is [24, 43] the target: 58\n",
      "when input is [24, 43, 58] the target: 5\n",
      "when input is [24, 43, 58, 5] the target: 57\n",
      "when input is [24, 43, 58, 5, 57] the target: 1\n",
      "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
      "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
      "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
      "when input is [44] the target: 53\n",
      "when input is [44, 53] the target: 56\n",
      "when input is [44, 53, 56] the target: 1\n",
      "when input is [44, 53, 56, 1] the target: 58\n",
      "when input is [44, 53, 56, 1, 58] the target: 46\n",
      "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
      "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
      "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52] the target: 58\n",
      "when input is [52, 58] the target: 1\n",
      "when input is [52, 58, 1] the target: 58\n",
      "when input is [52, 58, 1, 58] the target: 46\n",
      "when input is [52, 58, 1, 58, 46] the target: 39\n",
      "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
      "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
      "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
      "when input is [25] the target: 17\n",
      "when input is [25, 17] the target: 27\n",
      "when input is [25, 17, 27] the target: 10\n",
      "when input is [25, 17, 27, 10] the target: 0\n",
      "when input is [25, 17, 27, 10, 0] the target: 21\n",
      "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
      "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
      "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 \n",
    "block_size = 8\n",
    "def get_batch(split):\n",
    "    data = train if split == 'train' else valid\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i+block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"inputs:\")\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets = None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            #B, T, C are batch time and channel\n",
    "            B, T, C = logits.shape\n",
    "            #This is to reshape it as B, C, T as thats how pytorch wants it\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            #This will only take the last target value from B, C, T\n",
    "            logits = logits[:, -1, :]\n",
    "            #Apply softmax and get the probabilities\n",
    "            prob = F.softmax(logits, dim=-1)#B, C\n",
    "            #this is to sample from the distribution\n",
    "            idx_next = torch.multinomial(prob, num_samples=1)#B, 1\n",
    "            #This will append the sampled index into the running sequence so from B, T you will get B, T+1 T+2 T+3 and so on\n",
    "            idx = torch.cat((idx, idx_next), dim=1)#B, T+1\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(loss)\n",
    "#Here we start from a tensor or 0,0 so basically start from 0 and then generate so on\n",
    "print(decoded(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADAMW is a good optimizer for llms and stuff\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5727508068084717\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "#simple training loop of 10000 iterations\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iyoteng h hasbe pave pirance\n",
      "Rie hicomyonthar's\n",
      "Plinseard ith henoure wounonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KIN d pe wither vouprrouthercc.\n",
      "hathe; d!\n",
      "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
      "h hay.JUCle n prids, r loncave w hollular s O:\n",
      "HIs; ht anjx?\n",
      "\n",
      "DUThinqunt.\n",
      "\n",
      "LaZAnde.\n",
      "athave l.\n",
      "KEONH:\n",
      "ARThanco be y,-hedarwnoddy scace, tridesar, wnl'shenous s ls, theresseys\n",
      "PlorseelapinghiybHen yof GLUCEN t l-t E:\n",
      "I hisgothers je are!-e!\n",
      "QLYotouciullle'z\n"
     ]
    }
   ],
   "source": [
    "#as we can see the decoded predicted values are much better than whatever sequence we got above\n",
    "print(decoded(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b = \n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c = \n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "#this entire proccess is done as its more efficient than for loops, here basically current token interacts with all tokens before it to predict the next one and we use matrix multiplication instead of for loop\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))#creates triangular matrix\n",
    "a /= torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"a = \")\n",
    "print(a)\n",
    "print(\"b = \")\n",
    "print(b)\n",
    "print(\"c = \")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]#this takes all the tokens before the current token\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is same thing as above except instead of taking the token as it is we take the weights and multiply\n",
    "weights = torch.tril(torch.ones(T, T))\n",
    "weights = weights/ weights.sum(1, keepdim=True)\n",
    "xbow2 = weights @ x\n",
    "torch.allclose(xbow, xbow2)#checks if xbow and xbow2 are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we do the same as above except we use softmax which is basically taking the exponent and then normalising it out\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))#here basically if there is a 0 in the matrix replace it with -infinity so that we can take the exponential and future cant communicate with the past\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "xbow3 = weights @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from above we can see that the values in each row are uniform which isnt good because it means we're giving same importance to all tokens. self attention solves this issue by giving more importance to 1 token over others etc\n",
    "- the way self attention actually solves this is that each token is given a key and query. Query is basically what the token wants and key is what the token contains and the value is the best match to the current token\n",
    "- the weight is the dot product of key and query which basically gives the affinity or attention to be given to that token\n",
    "- a head is basically a mini-brain that helps the model selectively focus on certain aspects of the input data\n",
    "- one thing to note is the elements across the batch dimension do not interfere with each other\n",
    "- but in some cases you may want all tokens to interact with each other that is past and future tokens can interact. this is in case of things such as sentiment analysis where you want to see if something is good or bad with respect to the entire context and not just the past and present\n",
    ". in these cases you can just delete the tril part of the code because it means all tokens can interact with each other\n",
    "- in self attention the same token produces keys, queries and values but in case of cross attention queries can be produced from 1 nodes and keys and values are produced by other nodes\n",
    "- after getting the weight we must scale them or else it will be in order of the head size which is why we divide the weight by the square root of head size, in order to get it in 0-1 range. if you dont do this then softmax will give very extreme values\n",
    "- ![image.png](attachment:image.png)\n",
    "- multi-head attention is basically many self-attention heads working in parallel\n",
    "- feed forward is basically the thinking part of the attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.8991e-01,  8.6736e-01,  1.5501e-01, -6.5131e-01, -2.7023e-01,\n",
       "           7.8589e-01,  5.7559e-02, -4.9535e-01, -9.7129e-01,  3.4192e-01,\n",
       "           1.8012e-01, -7.4462e-01, -3.9583e-01, -5.3873e-01,  4.4231e-01,\n",
       "           5.4113e-01],\n",
       "         [ 5.4365e-01, -5.6043e-01, -2.5430e-01,  4.4537e-01, -2.5532e-01,\n",
       "          -2.5607e-01, -4.7274e-01, -8.0318e-02, -1.3331e-01,  8.7804e-01,\n",
       "           7.1691e-01, -2.6675e-01,  4.1206e-01,  2.9041e-01,  8.5100e-02,\n",
       "           1.2417e+00],\n",
       "         [ 3.4949e-01, -1.1961e-01, -4.1205e-01,  3.0803e-01,  3.0768e-02,\n",
       "          -1.3053e-01, -2.6905e-02,  5.0101e-02, -3.3306e-01, -2.2600e-01,\n",
       "           2.8263e-01,  1.2588e-02, -2.0410e-01, -1.2035e-01,  1.4451e-02,\n",
       "           1.1896e+00],\n",
       "         [ 6.4300e-02,  2.7288e-01, -1.3678e-01, -1.3444e-01, -6.0558e-02,\n",
       "           2.3449e-01, -1.5048e-02, -2.1652e-01, -5.4869e-01,  2.2054e-01,\n",
       "           1.5680e-01, -3.5360e-01, -1.6247e-01, -2.1488e-01,  3.5082e-01,\n",
       "           7.3793e-01],\n",
       "         [ 1.1827e-01,  7.2184e-01,  5.8735e-01,  3.8266e-01,  1.3330e-01,\n",
       "           7.9734e-01,  5.1634e-01,  3.8246e-01, -6.7740e-01, -9.2950e-01,\n",
       "          -3.0714e-01, -4.2845e-01, -8.2000e-01,  7.9067e-02,  1.7897e-02,\n",
       "           6.0729e-01],\n",
       "         [ 2.0999e-01,  4.8332e-01,  4.6597e-01,  4.3385e-01,  5.7060e-02,\n",
       "           6.2058e-01,  3.3932e-01,  3.2380e-01, -5.7371e-01, -6.1926e-01,\n",
       "          -1.1325e-01, -4.0449e-01, -6.0379e-01,  1.4520e-01,  4.7284e-03,\n",
       "           7.3673e-01],\n",
       "         [ 5.3806e-02, -1.0908e-01, -1.4951e-01,  4.3694e-01, -4.3897e-02,\n",
       "           3.2270e-02, -2.4784e-01, -1.2491e-01, -1.6028e-01,  4.7814e-01,\n",
       "           3.1292e-01, -7.3736e-02,  1.8466e-01,  1.1286e-01,  3.5353e-01,\n",
       "           7.3263e-01],\n",
       "         [-2.6465e-03, -4.5559e-02, -5.0296e-01,  4.1760e-01,  1.4308e-01,\n",
       "          -2.2444e-01, -1.1688e-01,  4.0717e-01, -9.4468e-03,  1.8508e-01,\n",
       "           1.8652e-02,  1.6901e-01,  3.8467e-01, -2.1804e-01,  1.1744e-01,\n",
       "           3.0762e-01]],\n",
       "\n",
       "        [[-1.4582e+00,  1.1108e+00,  2.2276e-01, -1.6862e-01, -1.3497e-01,\n",
       "           8.3278e-01,  8.5269e-01,  4.2509e-01, -7.5016e-01, -6.7192e-02,\n",
       "          -1.3500e+00,  2.6209e-01,  1.0455e+00, -1.1333e+00, -2.4144e-01,\n",
       "          -4.7425e-01],\n",
       "         [-5.1615e-01, -2.0931e-01,  8.1950e-02,  3.1667e-01, -2.1435e-01,\n",
       "           1.7153e-01,  2.6528e-01, -2.1490e-01, -2.7798e-01,  1.3361e-01,\n",
       "           4.8834e-01,  3.9174e-01,  6.5006e-02, -4.7741e-01, -7.8555e-02,\n",
       "          -4.9451e-01],\n",
       "         [-1.2428e+00,  3.1062e-01,  4.6404e-01,  6.7481e-02,  1.2710e-01,\n",
       "           1.9265e-01,  2.0874e-01,  2.9146e-01,  1.9513e-01,  1.4808e-01,\n",
       "          -2.8923e-02,  3.3155e-01,  8.2972e-01, -2.5195e-01,  4.2741e-01,\n",
       "          -1.1573e-01],\n",
       "         [-1.1047e+00,  4.4851e-01,  4.1698e-01,  1.1385e-01,  3.1131e-02,\n",
       "           4.5088e-01,  3.6452e-01,  2.7841e-01, -1.3435e-01,  1.5540e-01,\n",
       "          -3.9457e-01,  2.8515e-01,  7.8826e-01, -4.8355e-01,  1.8276e-01,\n",
       "          -2.3154e-01],\n",
       "         [ 2.0308e-01, -9.8641e-02,  9.3010e-01,  9.0419e-01,  5.3034e-02,\n",
       "           8.6767e-01, -1.1230e-01,  3.1673e-01,  3.3315e-02,  8.3573e-01,\n",
       "          -5.4543e-02, -2.3105e-02,  3.8321e-01,  1.4050e-01,  3.1263e-01,\n",
       "          -3.9157e-02],\n",
       "         [ 3.7060e-02,  1.8266e-02,  8.0906e-01,  7.4787e-01, -2.3051e-02,\n",
       "           7.8486e-01, -2.0050e-02,  3.3431e-01, -2.5863e-02,  7.2246e-01,\n",
       "          -4.1318e-02,  1.4938e-04,  4.1442e-01,  4.2433e-03,  2.5918e-01,\n",
       "          -1.2903e-01],\n",
       "         [-8.6279e-02,  1.4492e-01,  3.9109e-01,  3.0727e-01, -3.3902e-01,\n",
       "           2.7278e-01, -1.0521e-01,  2.4585e-01, -9.1899e-02,  6.0513e-01,\n",
       "           3.4744e-01, -2.0599e-01,  4.2268e-01, -4.2865e-01,  1.4593e-01,\n",
       "          -4.8792e-01],\n",
       "         [-6.7174e-01,  7.4282e-01,  3.2383e-01, -2.7416e-02, -3.9474e-01,\n",
       "           4.7408e-01,  3.3460e-01,  5.8653e-01, -2.6772e-01,  3.1063e-01,\n",
       "          -2.0646e-01, -9.4572e-02,  7.1726e-01, -7.0158e-01,  5.9991e-02,\n",
       "          -5.3736e-01]],\n",
       "\n",
       "        [[-6.3851e-02,  1.2120e+00, -4.1844e-01, -3.9381e-02, -8.1958e-01,\n",
       "          -2.5287e-01,  1.2273e+00, -6.5736e-01,  3.5395e-01, -1.1241e-01,\n",
       "           1.1924e-01,  1.0173e+00, -6.3597e-01, -1.2836e+00,  9.9429e-01,\n",
       "          -5.8972e-01],\n",
       "         [-5.9653e-01,  6.2535e-01, -1.6493e-01, -2.0161e-03, -7.2136e-01,\n",
       "          -4.6461e-01,  1.8977e-01, -2.9267e-01,  3.7378e-01, -3.4655e-02,\n",
       "           1.9611e-01,  2.2530e-01, -2.7363e-01, -8.2536e-01,  5.0644e-01,\n",
       "           3.9838e-02],\n",
       "         [-7.7322e-01,  1.2558e-01, -6.7511e-02,  1.9959e-02, -5.7962e-01,\n",
       "          -5.8357e-01, -2.1342e-01, -2.2090e-01,  4.2267e-01,  5.4805e-02,\n",
       "           4.8710e-01, -5.5375e-02, -2.1268e-01, -4.1812e-01,  5.5065e-01,\n",
       "           3.8527e-01],\n",
       "         [-8.0470e-01,  1.1243e-01,  6.6881e-02, -8.9963e-04, -3.0613e-01,\n",
       "          -5.2826e-01, -7.2538e-01,  7.9436e-02,  2.4648e-01,  2.2949e-01,\n",
       "           7.1979e-02, -3.9077e-01,  1.8549e-02, -2.3685e-01,  1.0256e-01,\n",
       "           4.2127e-01],\n",
       "         [-1.4705e-01,  1.0068e+00, -3.5442e-01, -3.3131e-02, -6.8580e-01,\n",
       "          -2.8543e-01,  9.5092e-01, -5.4032e-01,  3.1695e-01, -2.9985e-02,\n",
       "           1.2252e-01,  8.3668e-01, -5.5516e-01, -1.0848e+00,  8.8928e-01,\n",
       "          -4.6152e-01],\n",
       "         [-7.7135e-01, -8.9260e-02, -3.7160e-01,  3.0889e-01, -1.9276e-01,\n",
       "          -3.1244e-01,  3.6469e-02,  2.0243e-01,  2.8273e-01,  1.0895e-01,\n",
       "           2.5318e-01,  3.3203e-01, -1.2754e-01, -3.4766e-01,  5.0357e-01,\n",
       "          -2.0097e-01],\n",
       "         [-3.5643e-01, -6.8044e-02, -1.8946e-01,  3.7366e-01,  1.2623e-01,\n",
       "          -1.2240e-01, -2.8220e-01,  3.6102e-01,  1.9017e-02,  4.1192e-01,\n",
       "          -4.6713e-02,  2.1911e-01,  3.5557e-02,  5.9228e-02,  2.7360e-01,\n",
       "          -2.8063e-01],\n",
       "         [-3.8099e-01,  1.3572e-01, -3.5684e-01,  3.0209e-01,  3.8795e-02,\n",
       "          -1.6729e-01,  4.3511e-02,  1.1701e-01,  1.2785e-01,  4.0930e-01,\n",
       "           5.9103e-02,  2.7632e-01, -1.1901e-01, -2.2647e-01,  5.4506e-01,\n",
       "           2.1869e-02]],\n",
       "\n",
       "        [[-3.5593e-02,  4.4575e-02, -1.1118e-01,  8.4422e-02, -2.6740e-01,\n",
       "          -8.0212e-01, -1.7937e-01, -6.4606e-01, -2.9943e-01,  1.2506e+00,\n",
       "           2.3823e-01, -1.1776e-01, -9.9795e-02,  9.5056e-02, -4.5437e-01,\n",
       "           1.5093e+00],\n",
       "         [ 6.0279e-02, -2.2304e-01, -3.5308e-01,  3.3675e-01, -3.0532e-01,\n",
       "          -7.0691e-01, -6.8739e-01, -6.6323e-01, -2.8961e-01,  8.5538e-01,\n",
       "           2.4027e-01, -1.4937e-01, -8.4736e-02,  5.9289e-02, -5.5457e-01,\n",
       "           1.2133e+00],\n",
       "         [ 1.5836e-01, -4.9616e-01, -5.9905e-01,  5.9585e-01, -3.4566e-01,\n",
       "          -6.0546e-01, -1.2058e+00, -6.8134e-01, -2.8106e-01,  4.4387e-01,\n",
       "           2.4065e-01, -1.8141e-01, -6.9295e-02,  2.4412e-02, -6.5529e-01,\n",
       "           9.0592e-01],\n",
       "         [ 4.2712e-02, -4.6986e-02, -2.1174e-01,  1.5872e-01, -3.4046e-01,\n",
       "          -5.2109e-01, -3.9585e-01, -5.9863e-01, -3.8440e-01,  6.1186e-01,\n",
       "           1.5400e-01, -1.3132e-01, -6.1050e-02,  1.1946e-01, -4.6952e-01,\n",
       "           1.0423e+00],\n",
       "         [ 4.0765e-02, -1.9235e-01, -2.8525e-01,  2.5176e-02, -2.5686e-01,\n",
       "          -3.1173e-01, -6.0142e-01, -3.5779e-01, -3.8122e-01,  1.8462e-01,\n",
       "           1.7788e-01, -9.4463e-02,  1.3405e-02, -3.9559e-02, -5.1103e-01,\n",
       "           5.1243e-01],\n",
       "         [ 1.1401e-01, -4.8546e-01, -5.3477e-01,  4.4320e-01, -3.0262e-01,\n",
       "          -4.4722e-01, -1.1654e+00, -5.1337e-01, -2.8544e-01,  1.9135e-01,\n",
       "           2.2626e-01, -1.7974e-01, -8.9406e-03, -2.6367e-02, -6.3118e-01,\n",
       "           5.9850e-01],\n",
       "         [-5.3061e-01,  2.4643e-01,  4.9707e-01, -3.3757e-01, -1.4936e-01,\n",
       "          -2.8328e-01, -1.6890e-01,  1.3493e-01,  5.2150e-02,  3.2905e-01,\n",
       "           1.0786e-01, -7.7576e-01,  4.7446e-01,  2.8416e-01, -3.9533e-01,\n",
       "           4.9260e-01],\n",
       "         [-4.9205e-01,  2.1208e-02, -3.6367e-02, -1.9114e-02, -1.3337e-01,\n",
       "          -2.6598e-02, -4.3971e-01, -3.1843e-02, -6.5953e-01, -1.4032e-01,\n",
       "           1.5294e-01, -2.2536e-01,  1.5864e-01, -1.0015e-01, -4.8787e-01,\n",
       "           2.5574e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self attention approach\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=True)\n",
    "k = key(x) #B, T, 16\n",
    "q = query(x) #B, T, 16\n",
    "\n",
    "weights = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = weights @ v\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5728, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- residual block is important as it helps improve computation. basically you take a fork of the input perform the computation and send the output back to the residual pathway. residual pathway is just the input->target path\n",
    "- we must also add a dropout layer at the end so that its more efficient and reduces overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "weights = q @ k.transpose(-2, -1)*head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8793)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0217)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0032)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1335, -0.1059, -0.3824,  ..., -1.3422, -0.1971,  0.8795],\n",
       "        [-0.0353, -0.7439, -0.3371,  ..., -0.6276, -0.4846,  0.4556],\n",
       "        [ 0.3069, -1.5010,  1.4898,  ..., -0.6819,  0.9993,  0.8382],\n",
       "        ...,\n",
       "        [-1.6080, -1.6324, -0.7634,  ..., -0.9847,  0.0039, -0.8610],\n",
       "        [-0.2273,  0.0066, -0.2763,  ..., -0.8705, -1.2442, -0.7531],\n",
       "        [ 0.3054, -0.1505, -0.3809,  ..., -1.4962, -0.7711, -1.0681]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the below code is for batch layer normalisation which is basically batch normalisation but instead of columns we normalise rows\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class LayerNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        xmean = x.mean(1, keepdim=True)#batch mean\n",
    "        xvar = x.var(1, keepdim=True)#batch variance\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)#normalise to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100)#batch size 32 of 100 dimensional vectors\n",
    "x = module(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0].mean(), x[:, 0].std() #mean, std dev of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :].mean(), x[0, :].std() #mean, std dev of a single input from the batch of its features\n",
    "#this wont give you the exact predicted output (as in the sentences may not make sense) but it should give you a shakespearian like language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- note that this is a decoder model which basically means it just gives some random output based on input\n",
    "- in an encoder-decoder model, the input is encoded the computed then decoded (for example language translation)\n",
    "- in the encoder-decoder model there is no triangular mask so the tokens can freely interact with each other which is required to make senseful sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
